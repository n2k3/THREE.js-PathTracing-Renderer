<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0"
          name="viewport">
    <title>three.js PathTracing Renderer - glTF Viewer</title>
    <link href="css/default.css" rel="stylesheet"/>
</head>
<body>

<div id="container"></div>
<div id="info">three.js PathTracing Renderer - glTF Viewer</div>
<div id="cameraInfo">
    FOV: 72 / Aperture: 0.00 / FocusDistance: 100 <br>
    Samples: 0
</div>

<script src="js/three.min.js"></script>
<script src="js/BufferGeometryUtils.js"></script>
<script src="js/GLTFLoader.js"></script>
<script src="js/BVH_Acc_Structure_Iterative_Builder.js"></script>
<script src="js/pathTracingCommon.js"></script>
<script src="js/threex.keyboardstate.js"></script>
<script src="js/FirstPersonCameraControls.js"></script>
<script src="js/MobileJoystickControls.js"></script>
<script src="js/stats.min.js"></script>

<script>
    var SCREEN_WIDTH;
    var SCREEN_HEIGHT;
    var canvas, context;
    var container, stats;
    var controls;
    var pathTracingScene, screenTextureScene, screenOutputScene;
    var pathTracingUniforms, screenTextureUniforms, screenOutputUniforms; // HACK disable screenTextureUniforms, screenOutputUniforms;
	var PerlinNoiseTexture;
    var pathTracingDefines;
    var pathTracingGeometry, pathTracingMaterial, pathTracingMesh;
    var screenTextureGeometry, screenTextureMaterial, screenTextureMesh;
    var screenOutputGeometry, screenOutputMaterial, screenOutputMesh;
	var tallBoxGeometry, tallBoxMaterial, tallBoxMesh;
	var shortBoxGeometry, shortBoxMaterial, shortBoxMesh;
	var pathTracingRenderTarget, screenOutputRenderTarget; // HACK disable screenOutputRenderTarget
    var quadCamera, worldCamera;
    var renderer, clock;
    var frameTime, elapsedTime; // HACK disable elapsedTime
    var fovScale;
    var increaseFOV = false;
    var decreaseFOV = false;
    var apertureSize = 0.0;
    var increaseAperture = false;
    var decreaseAperture = false;
    var focusDistance = 100.0;
    var increaseFocusDist = false;
    var decreaseFocusDist = false;
    var pixelRatio = 1;
	var TWO_PI = Math.PI * 2;
	var sunAngle = 0;
	var sunDirection = new THREE.Vector3();
    var randomVector = new THREE.Vector3();
    var sampleCounter = 1.0;
    var frameCounter = 1.0;
    var keyboard = new THREEx.KeyboardState();
    var cameraIsMoving = false;
    var cameraJustStartedMoving = false;
    var cameraRecentlyMoving = false;
    var isPaused = true;
    var oldYawRotation, oldPitchRotation;
    var mobileJoystickControls = null;
    var oldDeltaX = 0, oldDeltaY = 0;
    var newDeltaX = 0, newDeltaY = 0;
    var mobileControlsMoveX = 0;
    var mobileControlsMoveY = 0;
    var stillFlagX = true, stillFlagY = true;
    var oldPinchWidthX = 0;
    var oldPinchWidthY = 0;
    var pinchDeltaX = 0;
    var pinchDeltaY = 0;
    var camFlightSpeed = 60;
	var cameraUnderWater = false;
    var fontAspect;
    var modelMesh;
    var modelScale = 1.0;
    var modelPositionOffset = new THREE.Vector3();
    var total_number_of_triangles = 0;
    var triangle_array;
    var materialNumber = 0;
    var triangleMaterialMarkers = [];
    var pathTracingMaterialList = [];
    var uniqueMaterialTextures = [];
    var meshList = [];
    var triangleDataTexture;
    var aabb_array;
    var aabbDataTexture;
    var totalWork;
    var vp0 = new THREE.Vector3();
    var vp1 = new THREE.Vector3();
    var vp2 = new THREE.Vector3();
    var vn0 = new THREE.Vector3();
    var vn1 = new THREE.Vector3();
    var vn2 = new THREE.Vector3();
    var vt0 = new THREE.Vector2();
    var vt1 = new THREE.Vector2();
    var vt2 = new THREE.Vector2();

    // the following variables will be used to calculate rotations and directions from the camera
    var cameraDirectionVector = new THREE.Vector3(); //for moving where the camera is looking
    var cameraRightVector = new THREE.Vector3(); //for strafing the camera right and left
    var cameraUpVector = new THREE.Vector3(); //for moving camera up and down
    var cameraWorldQuaternion = new THREE.Quaternion(); //for rotating scene objects to match camera's current rotation
    var cameraControlsObject; //for positioning and moving the camera itself
    var cameraControlsYawObject; //allows access to control camera's left/right movements through mobile input
    var cameraControlsPitchObject; //allows access to control camera's up/down movements through mobile input

    var PI_2 = Math.PI / 2; //used by controls below

    var infoElement = document.getElementById('info');
    infoElement.style.cursor = "default";
    infoElement.style.webkitUserSelect = "none";
    infoElement.style.MozUserSelect = "none";

    var cameraInfoElement = document.getElementById('cameraInfo');
    cameraInfoElement.style.cursor = "default";
    cameraInfoElement.style.webkitUserSelect = "none";
    cameraInfoElement.style.MozUserSelect = "none";

    var mouseControl = true;

    function onMouseWheel(event) {

        event.preventDefault();
        event.stopPropagation();

        if (event.deltaY > 0) {

            increaseFOV = true;

        } else if (event.deltaY < 0) {

            decreaseFOV = true;

        }

    }

    class MaterialObject {
        constructor(material) {
            // a list of material types and their corresponding numbers are found in the 'pathTracingCommon.js' file
            this.type = material.opacity < 1 ? 2 : 4; // default is 1 = diffuse opaque, 2 = glossy transparent, 4 = glossy opaque;
            this.albedoTextureID = -1; // which diffuse map to use for model's color, '-1' = no textures are used
            this.color = material.color ? material.color.copy(material.color) : new THREE.Color(1.0, 1.0, 1.0); // takes on different meanings, depending on 'type' above
            this.roughness = material.roughness || 0.0; // 0.0 to 1.0 range, perfectly smooth to extremely rough
            this.metalness = material.metalness || 0.0; // 0.0 to 1.0 range, usually either 0 or 1, either non-metal or metal
            this.opacity = material.opacity || 1.0; // 0.0 to 1.0 range, fully transparent to fully opaque
            this.refractiveIndex = this.type === 4 ? 1.4 : 1.5; // 1.0=air, 1.33=water, 1.4=clearCoat, 1.5=glass, etc.
            pathTracingMaterialList.push(this);
        }
    }

    console.time("LoadingGltf");

    var gltfLoader = new THREE.GLTFLoader();

    gltfLoader.load("models/00_003_002.gltf", function( meshGroup ) {
        if (meshGroup.scene)
            meshGroup = meshGroup.scene;

        let matrixStack = [];
        let parent;
        let totalTriangleCount = 0;
        matrixStack.push(new THREE.Matrix4());
        meshGroup.traverse( function ( child ) {
            if ( child.isMesh ) {
                if ( parent !== undefined && parent.name !== child.parent.name ) {
                    matrixStack.pop();
                    parent = undefined;
                }

                child.geometry.applyMatrix( child.matrix.multiply( matrixStack[matrixStack.length - 1] ) );

                if (child.material.length > 0) {
                    for (let i = 0; i < child.material.length; i++)
                        new MaterialObject(child.material[i]);
                } else {
                    new MaterialObject(child.material);
                }

                if (child.geometry.groups.length > 0) {
                    for (let i = 0; i < child.geometry.groups.length; i++) {
                        totalTriangleCount += child.geometry.groups[i].count / 3;
                        triangleMaterialMarkers.push(totalTriangleCount);
                    }
                } else {
                    totalTriangleCount += child.geometry.index.count / 3;
                    triangleMaterialMarkers.push(totalTriangleCount);
                }

                meshList.push(child);
            }
            else if ( child.isObject3D ) {
                if ( parent !== undefined )
                    matrixStack.pop();

                let matrixPeek = new THREE.Matrix4().copy( matrixStack[matrixStack.length - 1] ).multiply( child.matrix );
                matrixStack.push( matrixPeek );
                parent = child;
            }
        } );

        var geoList = [];
        for (let i = 0; i < meshList.length; i++)
            geoList.push(meshList[i].geometry);

        modelMesh = new THREE.Mesh(THREE.BufferGeometryUtils.mergeBufferGeometries(geoList));
        if (modelMesh.geometry.index)
            modelMesh.geometry = modelMesh.geometry.toNonIndexed(); // why do we need NonIndexed geometry?

        for (let i = 0; i < meshList.length; i++) {
            if (meshList[i].material.length > 0) {
                for (let j = 0; j < meshList[i].material.length; j++) {
                    if (meshList[i].material[j].map)
                        uniqueMaterialTextures.push(meshList[i].material[j].map);
                }
            }
            else if (meshList[i].material.map) {
                uniqueMaterialTextures.push(meshList[i].material.map);
            }
        }

        // Remove duplicate entries
        uniqueMaterialTextures = Array.from(new Set(uniqueMaterialTextures));

        for (let i = 0; i < meshList.length; i++) {
            if (meshList[i].material.length > 0) {
                for (let j = 0; j < meshList[i].material.length; j++) {
                    if (meshList[i].material[j].map) {
                        for (let k = 0; k < uniqueMaterialTextures.length; k++) {
                            if (meshList[i].material[j].map.image.src === uniqueMaterialTextures[k].image.src) {
                                pathTracingMaterialList[i].albedoTextureID = k;
                            }
                        }
                    }
                }
            }
            else if (meshList[i].material.map) {
                for (let j = 0; j < uniqueMaterialTextures.length; j++) {
                    if (meshList[i].material.map.image.src === uniqueMaterialTextures[j].image.src) {
                        pathTracingMaterialList[i].albedoTextureID = j;
                    }
                }
            }
        }

        // settings for scene model
        modelScale = 10.0;
        //modelMesh.geometry.rotateY(-Math.PI * 0.95);
        //modelPositionOffset.set(0, 4, -100);

        console.timeEnd("LoadingGltf");
        // now that the models have been loaded, we can init everything else
        init();

    });




    function init() {

        //#region "Init Three.js"
        console.time("InitThree");
        if ('ontouchstart' in window) {
            mouseControl = false;
            pixelRatio = 0.5;

            mobileJoystickControls = new MobileJoystickControls({
                //showJoystick: true,
                enableMultiTouch: true
            });
        }

        // if on mobile device, unpause the app because there is no ESC key and no mouse capture to do
        if (!mouseControl)
            isPaused = false;

        if (mouseControl) {

            window.addEventListener('wheel', onMouseWheel, false);

            document.body.addEventListener("click", function () {
                this.requestPointerLock = this.requestPointerLock || this.mozRequestPointerLock;
                this.requestPointerLock();
            }, false);

            window.addEventListener("click", function (event) {
                event.preventDefault();
            }, false);
            window.addEventListener("dblclick", function (event) {
                event.preventDefault();
            }, false);


            var pointerlockChange = function (event) {

                if (document.pointerLockElement === document.body ||
                    document.mozPointerLockElement === document.body || document.webkitPointerLockElement === document.body) {

                    isPaused = false;

                } else {

                    isPaused = true;

                }

            };

            // Hook pointer lock state change events
            document.addEventListener('pointerlockchange', pointerlockChange, false);
            document.addEventListener('mozpointerlockchange', pointerlockChange, false);
            document.addEventListener('webkitpointerlockchange', pointerlockChange, false);

        }

        canvas = document.createElement( 'canvas' );
        context = canvas.getContext( 'webgl2' );

        renderer = new THREE.WebGLRenderer( { canvas: canvas, context: context } );
        renderer.autoClear = false;
        // 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
        renderer.setPixelRatio(pixelRatio);
        renderer.setSize( window.innerWidth, window.innerHeight );
        //required by WebGL 2.0 for rendering to FLOAT textures
        renderer.context.getExtension('EXT_color_buffer_float');

        container = document.getElementById('container');
        container.appendChild(renderer.domElement);

        stats = new Stats();
        stats.domElement.style.position = 'absolute';
        stats.domElement.style.top = '0px';
        stats.domElement.style.cursor = "default";
        stats.domElement.style.webkitUserSelect = "none";
        stats.domElement.style.MozUserSelect = "none";
        container.appendChild(stats.domElement);

        window.addEventListener('resize', onWindowResize, false);

        clock = new THREE.Clock();

        pathTracingScene = new THREE.Scene();
        screenTextureScene = new THREE.Scene();
        screenOutputScene = new THREE.Scene();

        // quadCamera is simply the camera to help render the full screen quad (2 triangles),
        // hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
        // the window into our 3d world. This camera will not move or rotate for the duration of the app.
        quadCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
        screenTextureScene.add(quadCamera);
        screenOutputScene.add(quadCamera);

        // worldCamera is the dynamic camera 3d object that will be positioned, oriented and
        // constantly updated inside the 3d scene.  Its view will ultimately get passed back to the
        // stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
        worldCamera = new THREE.PerspectiveCamera(72, 1, 1, 1000); // TODO try 72, window.innerWidth / window.innerHeight, 1, 1000);
        pathTracingScene.add(worldCamera);

        controls = new FirstPersonCameraControls(worldCamera);

        cameraControlsObject = controls.getObject();
        cameraControlsYawObject = controls.getYawObject();
        cameraControlsPitchObject = controls.getPitchObject();

        pathTracingScene.add(cameraControlsObject);

        // for flyCam
        cameraControlsObject.position.set(30, 40, 50);

        // look slightly downward
        cameraControlsPitchObject.rotation.x = -0.2;

        oldYawRotation = cameraControlsYawObject.rotation.y;
        oldPitchRotation = cameraControlsPitchObject.rotation.x;

        // now that we moved and rotated the camera, the following line force-updates the camera's matrix,
        // and prevents rendering the very first frame in the old default camera position/orientation
        cameraControlsObject.updateMatrixWorld(true);

        pathTracingRenderTarget = new THREE.WebGLRenderTarget((window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
            minFilter: THREE.NearestFilter,
            magFilter: THREE.NearestFilter,
            format: THREE.RGBAFormat,
            type: THREE.FloatType,
            depthBuffer: false,
            stencilBuffer: false
        });

        screenTextureRenderTarget = new THREE.WebGLRenderTarget((window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
            minFilter: THREE.NearestFilter,
            magFilter: THREE.NearestFilter,
            format: THREE.RGBAFormat,
            type: THREE.FloatType,
            depthBuffer: false,
            stencilBuffer: false
        });

        console.timeEnd("InitThree");
        //#endregion "Init Three.js"

        // divide by 9 because of nonIndexed geometry (each triangle has 3 floats with each float constisting of 3 components)
        total_number_of_triangles = modelMesh.geometry.attributes.position.array.length / 9;
        console.log("Triangle count: " + total_number_of_triangles);

        console.time("BvhGeneration");
        totalWork = new Uint32Array(total_number_of_triangles);

        // Initialize triangle and aabb arrays where 2048 = width and height of texture and 4 are the r, g, b and a components
        triangle_array = new Float32Array(2048 * 2048 * 4);
        aabb_array = new Float32Array(2048 * 2048 * 4);

        var triangle_b_box_min = new THREE.Vector3();
        var triangle_b_box_max = new THREE.Vector3();
        var triangle_b_box_centroid = new THREE.Vector3();

        var vpa = new Float32Array(modelMesh.geometry.attributes.position.array);
        if (modelMesh.geometry.attributes.normal === undefined)
            modelMesh.geometry.computeVertexNormals();
        var vna = new Float32Array(modelMesh.geometry.attributes.normal.array);

        var modelHasUVs = false;
        if (modelMesh.geometry.attributes.uv !== undefined) {
            var vta = new Float32Array(modelMesh.geometry.attributes.uv.array);
            modelHasUVs = true;
        }

        for (let i = 0; i < total_number_of_triangles; i++) {

            triangle_b_box_min.set(Infinity, Infinity, Infinity);
            triangle_b_box_max.set(-Infinity, -Infinity, -Infinity);

            // record vertex texture coordinates (UVs)
            if (modelHasUVs) {
                vt0.set(vta[6 * i + 0], vta[6 * i + 1]);
                vt1.set(vta[6 * i + 2], vta[6 * i + 3]);
                vt2.set(vta[6 * i + 4], vta[6 * i + 5]);
            } else {
                vt0.set(-1, -1);
                vt1.set(-1, -1);
                vt2.set(-1, -1);
            }

            // record vertex normals
            vn0.set(vna[9 * i + 0], vna[9 * i + 1], vna[9 * i + 2]).normalize();
            vn1.set(vna[9 * i + 3], vna[9 * i + 4], vna[9 * i + 5]).normalize();
            vn2.set(vna[9 * i + 6], vna[9 * i + 7], vna[9 * i + 8]).normalize();

            // record vertex positions
            vp0.set(vpa[9 * i + 0], vpa[9 * i + 1], vpa[9 * i + 2]);
            vp1.set(vpa[9 * i + 3], vpa[9 * i + 4], vpa[9 * i + 5]);
            vp2.set(vpa[9 * i + 6], vpa[9 * i + 7], vpa[9 * i + 8]);

            vp0.multiplyScalar(modelScale);
            vp1.multiplyScalar(modelScale);
            vp2.multiplyScalar(modelScale);

            vp0.add(modelPositionOffset);
            vp1.add(modelPositionOffset);
            vp2.add(modelPositionOffset);

            //slot 0
            triangle_array[32 * i +  0] = vp0.x; // r or x
            triangle_array[32 * i +  1] = vp0.y; // g or y
            triangle_array[32 * i +  2] = vp0.z; // b or z
            triangle_array[32 * i +  3] = vp1.x; // a or w

            //slot 1
            triangle_array[32 * i +  4] = vp1.y; // r or x
            triangle_array[32 * i +  5] = vp1.z; // g or y
            triangle_array[32 * i +  6] = vp2.x; // b or z
            triangle_array[32 * i +  7] = vp2.y; // a or w

            //slot 2
            triangle_array[32 * i +  8] = vp2.z; // r or x
            triangle_array[32 * i +  9] = vn0.x; // g or y
            triangle_array[32 * i + 10] = vn0.y; // b or z
            triangle_array[32 * i + 11] = vn0.z; // a or w

            //slot 3
            triangle_array[32 * i + 12] = vn1.x; // r or x
            triangle_array[32 * i + 13] = vn1.y; // g or y
            triangle_array[32 * i + 14] = vn1.z; // b or z
            triangle_array[32 * i + 15] = vn2.x; // a or w

            //slot 4
            triangle_array[32 * i + 16] = vn2.y; // r or x
            triangle_array[32 * i + 17] = vn2.z; // g or y
            triangle_array[32 * i + 18] = vt0.x; // b or z
            triangle_array[32 * i + 19] = vt0.y; // a or w

            //slot 5
            triangle_array[32 * i + 20] = vt1.x; // r or x
            triangle_array[32 * i + 21] = vt1.y; // g or y
            triangle_array[32 * i + 22] = vt2.x; // b or z
            triangle_array[32 * i + 23] = vt2.y; // a or w

            // the remaining slots are used for PBR material properties

            if (i >= triangleMaterialMarkers[materialNumber])
                materialNumber++;

            //slot 6
            triangle_array[32 * i + 24] = pathTracingMaterialList[materialNumber].type; // r or x
            triangle_array[32 * i + 25] = pathTracingMaterialList[materialNumber].color.r; // g or y
            triangle_array[32 * i + 26] = pathTracingMaterialList[materialNumber].color.g; // b or z
            triangle_array[32 * i + 27] = pathTracingMaterialList[materialNumber].color.b; // a or w

            //slot 7
            triangle_array[32 * i + 28] = pathTracingMaterialList[materialNumber].albedoTextureID; // r or x
            triangle_array[32 * i + 29] = 0; // g or y
            triangle_array[32 * i + 30] = 0; // b or z
            triangle_array[32 * i + 31] = 0; // a or w

            triangle_b_box_min.copy(triangle_b_box_min.min(vp0));
            triangle_b_box_max.copy(triangle_b_box_max.max(vp0));
            triangle_b_box_min.copy(triangle_b_box_min.min(vp1));
            triangle_b_box_max.copy(triangle_b_box_max.max(vp1));
            triangle_b_box_min.copy(triangle_b_box_min.min(vp2));
            triangle_b_box_max.copy(triangle_b_box_max.max(vp2));

            triangle_b_box_centroid.set((triangle_b_box_min.x + triangle_b_box_max.x) * 0.5,
                (triangle_b_box_min.y + triangle_b_box_max.y) * 0.5,
                (triangle_b_box_min.z + triangle_b_box_max.z) * 0.5);

            aabb_array[9 * i + 0] = triangle_b_box_min.x;
            aabb_array[9 * i + 1] = triangle_b_box_min.y;
            aabb_array[9 * i + 2] = triangle_b_box_min.z;
            aabb_array[9 * i + 3] = triangle_b_box_max.x;
            aabb_array[9 * i + 4] = triangle_b_box_max.y;
            aabb_array[9 * i + 5] = triangle_b_box_max.z;
            aabb_array[9 * i + 6] = triangle_b_box_centroid.x;
            aabb_array[9 * i + 7] = triangle_b_box_centroid.y;
            aabb_array[9 * i + 8] = triangle_b_box_centroid.z;

            totalWork[i] = i;

        } // end for (let i = 0; i < total_number_of_triangles; i++)

        // Build the BVH acceleration structure, which places a bounding box ('root' of the tree) around all of the
        // triangles of the entire mesh, then subdivides each box into 2 smaller boxes.  It continues until it reaches 1 triangle,
        // which it then designates as a 'leaf'
        BVH_Build_Iterative(totalWork);
        //console.log(buildnodes);

        // Copy the buildnodes array into the aabb_array
        for (let n = 0; n < buildnodes.length; n++) {

            // slot 0
            aabb_array[8 * n + 0] = buildnodes[n].idLeftChild;  // r or x component
            aabb_array[8 * n + 1] = buildnodes[n].minCorner.x;  // g or y component
            aabb_array[8 * n + 2] = buildnodes[n].minCorner.y;  // b or z component
            aabb_array[8 * n + 3] = buildnodes[n].minCorner.z;  // a or w component

            // slot 1
            aabb_array[8 * n + 4] = buildnodes[n].idRightChild; // r or x component
            aabb_array[8 * n + 5] = buildnodes[n].maxCorner.x;  // g or y component
            aabb_array[8 * n + 6] = buildnodes[n].maxCorner.y;  // b or z component
            aabb_array[8 * n + 7] = buildnodes[n].maxCorner.z;  // a or w component

        }

        triangleDataTexture = new THREE.DataTexture(triangle_array,
            2048,
            2048,
            THREE.RGBAFormat,
            THREE.FloatType,
            THREE.Texture.DEFAULT_MAPPING,
            THREE.ClampToEdgeWrapping,
            THREE.ClampToEdgeWrapping,
            THREE.NearestFilter,
            THREE.NearestFilter,
            1,
            THREE.LinearEncoding
        );

        triangleDataTexture.flipY = false;
        triangleDataTexture.generateMipmaps = false;
        triangleDataTexture.needsUpdate = true;

        aabbDataTexture = new THREE.DataTexture(aabb_array,
            2048,
            2048,
            THREE.RGBAFormat,
            THREE.FloatType,
            THREE.Texture.DEFAULT_MAPPING,
            THREE.ClampToEdgeWrapping,
            THREE.ClampToEdgeWrapping,
            THREE.NearestFilter,
            THREE.NearestFilter,
            1,
            THREE.LinearEncoding
        );

        aabbDataTexture.flipY = false;
        aabbDataTexture.generateMipmaps = false;
        aabbDataTexture.needsUpdate = true;

        console.timeEnd("BvhGeneration");
        console.time("SceneSetup");
		
		PerlinNoiseTexture = new THREE.TextureLoader().load( 'textures/perlin256.png' );
		PerlinNoiseTexture.wrapS = THREE.RepeatWrapping;
		PerlinNoiseTexture.wrapT = THREE.RepeatWrapping;
		PerlinNoiseTexture.flipY = false;
		PerlinNoiseTexture.minFilter = THREE.LinearFilter;
		PerlinNoiseTexture.magFilter = THREE.LinearFilter;
		PerlinNoiseTexture.generateMipmaps = false;
		
        pathTracingGeometry = new THREE.PlaneBufferGeometry(2, 2);

        pathTracingUniforms = {

            tPreviousTexture: { type: "t", value: screenTextureRenderTarget.texture },
            tTriangleTexture: { type: "t", value: triangleDataTexture },
            tAABBTexture: { type: "t", value: aabbDataTexture },
            tAlbedoTextures: { type: "t", value: uniqueMaterialTextures },
			t_PerlinNoise: { type: "t", value: PerlinNoiseTexture },
            uCameraIsMoving: { type: "b1", value: false },
            uCameraJustStartedMoving: { type: "b1", value: false },

			uCameraUnderWater: { type: "f", value: 0.0 },
            uTime: { type: "f", value: 0.0 },
            uSampleCounter: { type: "f", value: 1.0 }, // HACK try value 0.0
            uFrameCounter: { type: "f", value: 1.0 },
            uULen: { type: "f", value: 1.0 },
            uVLen: { type: "f", value: 1.0 },
            uApertureSize: { type: "f", value: 0.0 },
            uFocusDistance: { type: "f", value: 100.0 },

            uResolution: { type: "v2", value: new THREE.Vector2() },

            uRandomVector: { type: "v3", value: new THREE.Vector3() },
			uSunDirection: { type: "v3", value: new THREE.Vector3() },
            uCameraMatrix: {type: "m4", value: new THREE.Matrix4() },

			uShortBoxInvMatrix: { type: "m4", value: new THREE.Matrix4() },
			uShortBoxNormalMatrix: { type: "m3", value: new THREE.Matrix3() },

			uTallBoxInvMatrix: { type: "m4", value: new THREE.Matrix4() },
			uTallBoxNormalMatrix: { type: "m3", value: new THREE.Matrix3() }

        };

        pathTracingDefines = {
            //N_ALBEDO_MAPS: uniqueMaterialTextures.length
        };

        pathTracingMesh = new THREE.Mesh(pathTracingGeometry, pathTracingMaterial);
        pathTracingScene.add(pathTracingMesh);

        screenTextureGeometry = new THREE.PlaneBufferGeometry(2, 2);

        screenTextureMaterial = new THREE.ShaderMaterial({
            uniforms: screenTextureShader.uniforms,
            vertexShader: screenTextureShader.vertexShader,
            fragmentShader: screenTextureShader.fragmentShader,
            depthWrite: false,
            depthTest: false
        });

        screenTextureMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;

        screenTextureMesh = new THREE.Mesh(screenTextureGeometry, screenTextureMaterial);
        screenTextureScene.add(screenTextureMesh);



        screenOutputGeometry = new THREE.PlaneBufferGeometry(2, 2);

        screenOutputMaterial = new THREE.ShaderMaterial({
            uniforms: screenOutputShader.uniforms,
            vertexShader: screenOutputShader.vertexShader,
            fragmentShader: screenOutputShader.fragmentShader,
            depthWrite: false,
            depthTest: false
        });

        screenOutputMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;

        screenOutputMesh = new THREE.Mesh(screenOutputGeometry, screenOutputMaterial);
        screenOutputScene.add(screenOutputMesh);

		// Boxes
		tallBoxGeometry = new THREE.BoxGeometry(1,1,1);
		tallBoxMaterial = new THREE.MeshPhysicalMaterial( {
			color: new THREE.Color(0.95, 0.95, 0.95), //RGB, ranging from 0.0 - 1.0
			roughness: 1.0 // ideal Diffuse material	
		} );
		
		tallBoxMesh = new THREE.Mesh(tallBoxGeometry, tallBoxMaterial);
		pathTracingScene.add(tallBoxMesh);
		tallBoxMesh.visible = false; // disable normal Three.js rendering updates of this object: 
		// it is just a data placeholder as well as an Object3D that can be transformed/manipulated by 
		// using familiar Three.js library commands. It is then fed into the GPU path tracing renderer
		// through its 'matrixWorld' matrix. See below:
		tallBoxMesh.rotation.set(0, Math.PI * 0.1, 0);
		tallBoxMesh.position.set(180, 170, -350);
		tallBoxMesh.updateMatrixWorld(true); // 'true' forces immediate matrix update
		
		pathTracingUniforms.uTallBoxInvMatrix.value.getInverse( tallBoxMesh.matrixWorld );
		pathTracingUniforms.uTallBoxNormalMatrix.value.getNormalMatrix( tallBoxMesh.matrixWorld );
		
		shortBoxGeometry = new THREE.BoxGeometry(1,1,1);
		shortBoxMaterial = new THREE.MeshPhysicalMaterial( {
			color: new THREE.Color(0.95, 0.95, 0.95), //RGB, ranging from 0.0 - 1.0
			roughness: 1.0 // ideal Diffuse material	
		} );
		
		shortBoxMesh = new THREE.Mesh(shortBoxGeometry, shortBoxMaterial);
		pathTracingScene.add(shortBoxMesh);
		shortBoxMesh.visible = false;
		shortBoxMesh.rotation.set(0, -Math.PI * 0.09, 0);
		shortBoxMesh.position.set(370, 85, -170);
		shortBoxMesh.updateMatrixWorld(true); // 'true' forces immediate matrix update
		
		pathTracingUniforms.uShortBoxInvMatrix.value.getInverse( shortBoxMesh.matrixWorld );
		pathTracingUniforms.uShortBoxNormalMatrix.value.getNormalMatrix( shortBoxMesh.matrixWorld );

        /*
        // Fullscreen API
        document.addEventListener("click", function() {

            if ( !document.fullscreenElement && !document.mozFullScreenElement && !document.webkitFullscreenElement ) {

                if (document.documentElement.requestFullscreen) {
                    document.documentElement.requestFullscreen();

                } else if (document.documentElement.mozRequestFullScreen) {
                    document.documentElement.mozRequestFullScreen();

                } else if (document.documentElement.webkitRequestFullscreen) {
                    document.documentElement.webkitRequestFullscreen();

                }

            }
        });
        */

        var loader = new THREE.FileLoader();

        //load vertex and fragment shader files that is used in the  pathTracing material, mesh and scene
        loader.load('shaders/vertex.glsl', (vertexShader) => {
            loader.load('shaders/fragment_combined_test.glsl', (fragmentShader) => {
                pathTracingMaterial = new THREE.ShaderMaterial({
                    uniforms: pathTracingUniforms,
                    defines: pathTracingDefines,
                    vertexShader: vertexShader,
                    fragmentShader: fragmentShader,
                    depthTest: false,
                    depthWrite: false
                });

                pathTracingMesh = new THREE.Mesh(pathTracingGeometry, pathTracingMaterial);
                pathTracingScene.add(pathTracingMesh);

                // the following keeps the large scene ShaderMaterial quad right in front
                //   of the camera at all times. This is necessary because without it, the scene
                //   quad will fall out of view and get clipped when the camera rotates past 180 degrees.
                worldCamera.add(pathTracingMesh);

                console.timeEnd("SceneSetup");
            });
        });

        // onWindowResize() must be at the end of the init() function
        onWindowResize();

        // everything is set up, now we can start animating
        animate();

    } // end function init()



    function onWindowResize(event) {
        // TODO fix the incremental rendering result's brightness being lower then before resize
        SCREEN_WIDTH = window.innerWidth;
        SCREEN_HEIGHT = window.innerHeight;

        renderer.setPixelRatio(pixelRatio);
        renderer.setSize(SCREEN_WIDTH, SCREEN_HEIGHT);

        fontAspect = (SCREEN_WIDTH / 175) * (SCREEN_HEIGHT / 200);
        if (fontAspect > 25) fontAspect = 25;
        if (fontAspect < 4) fontAspect = 4;
        fontAspect *= 2;

        pathTracingUniforms.uResolution.value.x = renderer.context.drawingBufferWidth;
        pathTracingUniforms.uResolution.value.y = renderer.context.drawingBufferHeight;

        pathTracingRenderTarget.setSize(renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight);
        screenTextureRenderTarget.setSize(renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight);

        worldCamera.aspect = renderer.domElement.clientWidth / renderer.domElement.clientHeight;
        worldCamera.updateProjectionMatrix();

        // the following scales all scene objects by the worldCamera's field of view,
        // taking into account the screen aspect ratio and multiplying the uniform uULen,
        // the x-coordinate, by this ratio
        fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
        pathTracingUniforms.uVLen.value = Math.tan(fovScale);
        pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;

        if (!mouseControl) {

            button1Element.style.display = "";
            button2Element.style.display = "";
            button3Element.style.display = "";
            button4Element.style.display = "";
            button5Element.style.display = "";
            button6Element.style.display = "";
            // check if mobile device is in portrait or landscape mode and position buttons accordingly
            if (SCREEN_WIDTH < SCREEN_HEIGHT) {

                button1Element.style.right = 36 + "%";
                button2Element.style.right = 2 + "%";
                button3Element.style.right = 16 + "%";
                button4Element.style.right = 16 + "%";
                button5Element.style.right = 3 + "%";
                button6Element.style.right = 3 + "%";

                button1Element.style.bottom = 5 + "%";
                button2Element.style.bottom = 5 + "%";
                button3Element.style.bottom = 13 + "%";
                button4Element.style.bottom = 2 + "%";
                button5Element.style.bottom = 25 + "%";
                button6Element.style.bottom = 18 + "%";

            } else {

                button1Element.style.right = 22 + "%";
                button2Element.style.right = 3 + "%";
                button3Element.style.right = 11 + "%";
                button4Element.style.right = 11 + "%";
                button5Element.style.right = 3 + "%";
                button6Element.style.right = 3 + "%";

                button1Element.style.bottom = 10 + "%";
                button2Element.style.bottom = 10 + "%";
                button3Element.style.bottom = 26 + "%";
                button4Element.style.bottom = 4 + "%";
                button5Element.style.bottom = 48 + "%";
                button6Element.style.bottom = 34 + "%";

            }

        } // end if ( !mouseControl ) {

    } // end function onWindowResize( event )



    function animate() {

        requestAnimationFrame(animate);

        frameTime = clock.getDelta();

        //elapsedTime = clock.getElapsedTime() % 1000;

        // reset flags
        cameraIsMoving = false;
        cameraJustStartedMoving = false;

        // check user controls
        if (mouseControl) {
            // movement detected
            if (oldYawRotation != cameraControlsYawObject.rotation.y ||
                oldPitchRotation != cameraControlsPitchObject.rotation.x) {

                cameraIsMoving = true;
            }

            // save state for next frame
            oldYawRotation = cameraControlsYawObject.rotation.y;
            oldPitchRotation = cameraControlsPitchObject.rotation.x;

        } // end if (mouseControl)

        // if not playing on desktop, get input from the mobileJoystickControls
        if (!mouseControl) {

            newDeltaX = joystickDeltaX;

            if (newDeltaX) {

                mobileControlsMoveX = oldDeltaX - newDeltaX;
                // smooth out jerkiness if camera was sitting still
                if (stillFlagX) {
                    mobileControlsMoveX *= 0.1;
                    stillFlagX = false;
                }
                // mobileJoystick X movement (left and right) affects camera rotation around the Y axis
                cameraControlsYawObject.rotation.y += (mobileControlsMoveX) * 0.01;
            }

            newDeltaY = joystickDeltaY;

            if (newDeltaY) {

                mobileControlsMoveY = oldDeltaY - newDeltaY;
                // smooth out jerkiness if camera was sitting still
                if (stillFlagY) {
                    mobileControlsMoveY *= 0.1;
                    stillFlagY = false;
                }
                // mobileJoystick Y movement (up and down) affects camera rotation around the X axis
                cameraControlsPitchObject.rotation.x += (mobileControlsMoveY) * 0.01;
            }

            // clamp the camera's vertical movement (around the x-axis) to the scene's 'ceiling' and 'floor',
            // so you can't accidentally flip the camera upside down
            cameraControlsPitchObject.rotation.x = Math.max(-PI_2, Math.min(PI_2, cameraControlsPitchObject.rotation.x));

            // save state for next frame
            oldDeltaX = newDeltaX;
            oldDeltaY = newDeltaY;

            // movement detected
            if (newDeltaX || newDeltaY) {

                cameraIsMoving = true;
            } else {
                stillFlagX = true;
                stillFlagY = true;
            }

            var newPinchWidthX = pinchWidthX;
            var newPinchWidthY = pinchWidthY;
            pinchDeltaX = newPinchWidthX - oldPinchWidthX;
            pinchDeltaY = newPinchWidthY - oldPinchWidthY;

            if (Math.abs(pinchDeltaX) > Math.abs(pinchDeltaY)) {
                if (pinchDeltaX < -3) increaseFOV = true;
                if (pinchDeltaX > 3) decreaseFOV = true;
            }

            if (Math.abs(pinchDeltaY) >= Math.abs(pinchDeltaX)) {
                if (pinchDeltaY > 1) increaseAperture = true;
                if (pinchDeltaY < -1) decreaseAperture = true;
            }

            // save state for next frame
            oldPinchWidthX = newPinchWidthX;
            oldPinchWidthY = newPinchWidthY;

        } // end if ( !mouseControl )

        // this gives us a vector in the direction that the camera is pointing,
        // which will be useful for moving the camera 'forward' and shooting projectiles in that direction
        controls.getDirection(cameraDirectionVector);
        cameraDirectionVector.normalize();
        controls.getUpVector(cameraUpVector);
        controls.getRightVector(cameraRightVector);

        // the following gives us a rotation quaternion (4D vector), which will be useful for
        // rotating scene objects to match the camera's rotation
        worldCamera.getWorldQuaternion(cameraWorldQuaternion);

        // allow flying camera
        if ((keyboard.pressed('W') || button3Pressed) && !(keyboard.pressed('S') || button4Pressed)) {

            cameraControlsObject.position.add(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
            cameraIsMoving = true;
        }
        if ((keyboard.pressed('S') || button4Pressed) && !(keyboard.pressed('W') || button3Pressed)) {

            cameraControlsObject.position.sub(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
            cameraIsMoving = true;
        }
        if ((keyboard.pressed('A') || button1Pressed) && !(keyboard.pressed('D') || button2Pressed)) {

            cameraControlsObject.position.sub(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
            cameraIsMoving = true;
        }
        if ((keyboard.pressed('D') || button2Pressed) && !(keyboard.pressed('A') || button1Pressed)) {

            cameraControlsObject.position.add(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
            cameraIsMoving = true;
        }
        if (keyboard.pressed('E') && !keyboard.pressed('Q')) {

            cameraControlsObject.position.add(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
            cameraIsMoving = true;
        }
        if (keyboard.pressed('Q') && !keyboard.pressed('E')) {

            cameraControlsObject.position.sub(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
            cameraIsMoving = true;
        }
        if ((keyboard.pressed('up') || button5Pressed) && !(keyboard.pressed('down') || button6Pressed)) {

            increaseFocusDist = true;
        }
        if ((keyboard.pressed('down') || button6Pressed) && !(keyboard.pressed('up') || button5Pressed)) {

            decreaseFocusDist = true;
        }
        if (keyboard.pressed('right') && !keyboard.pressed('left')) {

            increaseAperture = true;
        }
        if (keyboard.pressed('left') && !keyboard.pressed('right')) {

            decreaseAperture = true;
        }

        if (increaseFOV) {
            worldCamera.fov++;
            if (worldCamera.fov > 150)
                worldCamera.fov = 150;
            fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
            pathTracingUniforms.uVLen.value = Math.tan(fovScale);
            pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;

            cameraIsMoving = true;
            increaseFOV = false;
        }
        if (decreaseFOV) {
            worldCamera.fov--;
            if (worldCamera.fov < 1)
                worldCamera.fov = 1;
            fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
            pathTracingUniforms.uVLen.value = Math.tan(fovScale);
            pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;

            cameraIsMoving = true;
            decreaseFOV = false;
        }

        if (increaseFocusDist) {
            focusDistance += 1;
            pathTracingUniforms.uFocusDistance.value = focusDistance;
            cameraIsMoving = true;
            increaseFocusDist = false;
        }
        if (decreaseFocusDist) {
            focusDistance -= 1;
            if (focusDistance < 1)
                focusDistance = 1;
            pathTracingUniforms.uFocusDistance.value = focusDistance;
            cameraIsMoving = true;
            decreaseFocusDist = false;
        }

        if (increaseAperture) {
            apertureSize += 0.1;
            if (apertureSize > 20.0)
                apertureSize = 20.0;
            pathTracingUniforms.uApertureSize.value = apertureSize;
            cameraIsMoving = true;
            increaseAperture = false;
        }
        if (decreaseAperture) {
            apertureSize -= 0.1;
            if (apertureSize < 0.0)
                apertureSize = 0.0;
            pathTracingUniforms.uApertureSize.value = apertureSize;
            cameraIsMoving = true;
            decreaseAperture = false;
        }


        if ( cameraIsMoving ) {

            sampleCounter = 1.0;
            frameCounter  += 1.0;

            if ( !cameraRecentlyMoving ) {
                cameraJustStartedMoving = true;
                cameraRecentlyMoving = true;
            }

        }

        if ( !cameraIsMoving ) {

			//sampleCounter = 1.0; // for continuous updating of image
			sampleCounter += 1.0; // for progressive refinement of image
            frameCounter  += 1.0;
            if (cameraRecentlyMoving)
                frameCounter = 1.0;

            cameraRecentlyMoving = false;

        }
		
		/*
		if (cameraControlsObject.position.y < 0.0)
			cameraUnderWater = 1.0;
		else cameraUnderWater = 0.0;
		*/

		//sunAngle = (elapsedTime * 0.03) % Math.PI;
		sunAngle = Math.PI / 2.5;
		sunDirection.set(Math.cos(sunAngle) * 1.2, Math.sin(sunAngle), -Math.cos(sunAngle) * 3.0);
		sunDirection.normalize();

		//pathTracingUniforms.uCameraUnderWater.value = cameraUnderWater;
		pathTracingUniforms.uSunDirection.value.copy(sunDirection);
		//pathTracingUniforms.uTime.value = elapsedTime;
        pathTracingUniforms.uCameraIsMoving.value = cameraIsMoving;
        pathTracingUniforms.uCameraJustStartedMoving.value = cameraJustStartedMoving;
        pathTracingUniforms.uSampleCounter.value = sampleCounter;
        pathTracingUniforms.uFrameCounter.value = frameCounter;
        pathTracingUniforms.uRandomVector.value = randomVector.set(Math.random(), Math.random(), Math.random());
        // CAMERA
        cameraControlsObject.updateMatrixWorld(true);
        pathTracingUniforms.uCameraMatrix.value.copy(worldCamera.matrixWorld);
        screenOutputMaterial.uniforms.uOneOverSampleCounter.value = 1.0 / sampleCounter;

        cameraInfoElement.innerHTML = `FOV: ${worldCamera.fov} / Aperture: ${apertureSize.toFixed(2)} / FocusDistance: ${focusDistance}<br>Samples: ${sampleCounter}`;

        // RENDERING in 3 steps

        // STEP 1
        // Perform PathTracing and Render(save) into pathTracingRenderTarget
        // Read previous screenTextureRenderTarget to use as a new starting point to blend with
        renderer.render(pathTracingScene, worldCamera, pathTracingRenderTarget);

        // STEP 2
        // Render(copy) the final pathTracingScene output(above) into screenTextureRenderTarget
        // This will be used as a new starting point for Step 1 above
        renderer.render(screenTextureScene, quadCamera, screenTextureRenderTarget);

        // STEP 3
        // Render full screen quad with generated pathTracingRenderTarget in STEP 1 above.
        // After the image is gamma corrected, it will be shown on the screen as the final accumulated output
        renderer.render(screenOutputScene, quadCamera);

        stats.update();

    } // end function animate()
</script>

</body>
</html>